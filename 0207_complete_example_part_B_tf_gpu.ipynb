{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dd0dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install open3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b8cf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13103230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a85530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf26337",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bba3fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pyequilib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e9288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e983aa69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de7c087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fan_Z\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Fan_Z\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "C:\\Users\\Fan_Z\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import imageio as iio\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from equilib import Equi2Pers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b2a3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fd239ef",
   "metadata": {},
   "source": [
    "#### create point cloud from panorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb217c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnt = []  # 3D point list x0, y0, z0, x1, y1, z1, ...\n",
    "clr = []\n",
    "remove_x = []\n",
    "remove_y = []\n",
    "from PIL import Image\n",
    "\n",
    "x, y, xs, ys = 0, 0, 0, 0  # texture position and size\n",
    "a, b, r, da, db = 0.0, 0.0, 0.0, 0.0, 0.0  # spherical position and angle steps\n",
    "xx, yy, zz = 0.0, 0.0, 0.0  # 3D point\n",
    "    \n",
    "depth_img = Image.open('../Project-demo/sample_data/depth_predict_4.png')\n",
    "color_img = Image.open('../Project-demo/sample_data/test_img_4.jpg')\n",
    "\n",
    "xs, ys = depth_img.size\n",
    "\n",
    "# 180x90 deg\n",
    "da = 2.0 * 3.14 / (xs - 1)\n",
    "db = 1 * 3.14 / (ys - 1)\n",
    "b = -0.5 * 3.14\n",
    "depth_img_array = np.asarray(depth_img)\n",
    "depth_max = depth_img_array.max()\n",
    "\n",
    "\n",
    "b_spilt_0 = 0\n",
    "b_spilt = 1/(ys - 1)\n",
    "\n",
    "# Process all its pixels\n",
    "pnt.clear()\n",
    "for y in range(ys):\n",
    "    #from negative 90 to positive 90 vertically \n",
    "    b += db\n",
    "    b_spilt_0 += b_spilt\n",
    "    \n",
    "    for x in range(xs):\n",
    "        # from 0 to 360 horizontally \n",
    "        a += da\n",
    "\n",
    "        # Pixel access\n",
    "        r1 = depth_max - depth_img.getpixel((x, y))  # obtain intensity from texture <0..255>\n",
    "        \n",
    "        # remove the points within the central area\n",
    "            \n",
    "        r2 = r1/float(depth_max)  # normalize to <0..1>\n",
    "\n",
    "        # Convert to 3D\n",
    "        xx = 2 * r2 * np.cos(a) * np.cos(b)\n",
    "        yy = 2 * r2 * np.sin(a) * np.cos(b)\n",
    "        zz = (2*r2) ** 2 *np.sin(b)\n",
    "           \n",
    "        c = color_img.getpixel((x, y))\n",
    "        c0 = c[0]/255.0\n",
    "        c1 = c[1]/255.0\n",
    "        c2 = c[2]/255.0\n",
    "        \n",
    "        #pnt.append([xx,yy,zz])\n",
    "        #clr.append([c0,c1,c2])\n",
    "        \n",
    "        if r1>20 and zz <0.2:\n",
    "            pnt.append([xx,yy,zz])\n",
    "            clr.append([c0,c1,c2])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b6d9b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(pnt)\n",
    "pcd.colors = o3d.utility.Vector3dVector(np.array(clr))\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6324564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "735d9d25",
   "metadata": {},
   "source": [
    "#### create point cloud from splited image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f573e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.097152e+06, 0.000000e+00, 1.023500e+03],\n",
       "       [0.000000e+00, 1.048576e+06, 5.115000e+02],\n",
       "       [0.000000e+00, 0.000000e+00, 1.000000e+00]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PIL.Image as pil\n",
    "path = '../Project-demo/sample_data/depth_predict_4.png'\n",
    "depth_raw  = pil.open(path).convert('RGB')\n",
    "width,height = depth_raw.size\n",
    "\n",
    "FOV = 90\n",
    "f = 0.5 * width * 1 / np.tan(0.5 * FOV / 180.0 * np.pi)\n",
    "cx = (width - 1) / 2.0\n",
    "cy = (height - 1) / 2.0\n",
    "fx = f * width\n",
    "fy = f * height\n",
    "\n",
    "phc = o3d.camera.PinholeCameraIntrinsic()\n",
    "phc.set_intrinsics(width, height, fx, fy, cx, cy)\n",
    "phc.intrinsic_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc76bacc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23f9f416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGBDImage of size \n",
      "Color image : 720x720, with 1 channels.\n",
      "Depth image : 720x720, with 1 channels.\n",
      "Use numpy.asarray to access buffer data.\n",
      "RGBDImage of size \n",
      "Color image : 720x720, with 1 channels.\n",
      "Depth image : 720x720, with 1 channels.\n",
      "Use numpy.asarray to access buffer data.\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "for i in range(2):\n",
    "    \n",
    "    depth_file = '../Project-demo/sample_data/depth_predict_4_spilt_{}.png'.format(str(i))\n",
    "    rgb_file = '../Project-demo/sample_data/test_img_4_spilt_{}.png'.format(str(i))\n",
    "    \n",
    "    depth_image = o3d.io.read_image(depth_file)\n",
    "    rgb_image = o3d.io.read_image(rgb_file)\n",
    "    \n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(rgb_image,depth_image)\n",
    "    print(rgbd_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce92b563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: 不支持请求的转换操作。 \n"
     ]
    }
   ],
   "source": [
    "pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image, o3d.camera.PinholeCameraIntrinsic(o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault))\n",
    "pcd.transform([[1,0,0,0],[0,-1,0,0],[0,0,-1,0],[0,0,0,1]])\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48ff2a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5573f9ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu] *",
   "language": "python",
   "name": "conda-env-tf-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
